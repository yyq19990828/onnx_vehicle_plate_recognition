# polygraphy run - è·¨æ¡†æ¶æ¨ç†æ¯”è¾ƒ

`polygraphy run` æ˜¯ Polygraphy æœ€æ ¸å¿ƒçš„å‘½ä»¤ï¼Œç”¨äºåœ¨ä¸åŒæ¨ç†æ¡†æ¶é—´æ¯”è¾ƒæ¨¡å‹è¾“å‡ºï¼Œå‘ç°ç²¾åº¦é—®é¢˜å’Œæ€§èƒ½å·®å¼‚ã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½

- **è·¨æ¡†æ¶æ¯”è¾ƒ**: åŒæ—¶åœ¨å¤šä¸ªæ¡†æ¶ä¸Šè¿è¡Œæ¨¡å‹å¹¶æ¯”è¾ƒç»“æœ
- **é€å±‚è¾“å‡º**: æ”¯æŒæ ‡è®°æ‰€æœ‰ä¸­é—´å±‚è¾“å‡ºè¿›è¡Œè¯¦ç»†å¯¹æ¯”
- **è‡ªå®šä¹‰è¾“å…¥**: æ”¯æŒåŠ è½½è‡ªå®šä¹‰è¾“å…¥æ•°æ®æˆ–ä½¿ç”¨éšæœºæ•°æ®
- **å®¹å·®é…ç½®**: çµæ´»çš„è¯¯å·®å®¹å¿åº¦è®¾ç½®
- **ç»“æœä¿å­˜**: å¯ä¿å­˜è¾“å…¥è¾“å‡ºæ•°æ®ç”¨äºåç»­åˆ†æ

## ğŸ“‹ åŸºæœ¬ç”¨æ³•

### ç®€å•è·¨æ¡†æ¶æ¯”è¾ƒ
```bash
# ONNX Runtime vs TensorRT æ¯”è¾ƒ
polygraphy run model.onnx --onnxrt --trt

# åŒ…å«åŸå§‹ ONNX æ¡†æ¶
polygraphy run model.onnx --onnx --onnxrt --trt

# æŒ‡å®šç‰¹å®šç‰ˆæœ¬
polygraphy run model.onnx --onnxrt --trt --trt-min-shapes input:[1,3,224,224]
```

### é€å±‚è¾“å‡ºæ¯”è¾ƒ
```bash
# æ ‡è®°æ‰€æœ‰å±‚ä¸ºè¾“å‡º
polygraphy run model.onnx --onnxrt --trt --mark-all

# æŒ‡å®šç‰¹å®šå±‚
polygraphy run model.onnx --onnxrt --trt --onnx-outputs output1 output2
```

### è‡ªå®šä¹‰è¾“å…¥æ•°æ®
```bash
# ä» JSON æ–‡ä»¶åŠ è½½
polygraphy run model.onnx --onnxrt --trt --load-inputs inputs.json

# ä½¿ç”¨æ•°æ®ç”Ÿæˆè„šæœ¬
polygraphy run model.onnx --onnxrt --trt --data-loader-script data_loader.py

# æŒ‡å®šè¾“å…¥å½¢çŠ¶èŒƒå›´
polygraphy run model.onnx --onnxrt --trt --input-shapes input:[1,3,224,224]
```

## âš™ï¸ å¸¸ç”¨å‚æ•°è¯¦è§£

### æ¡†æ¶é€‰æ‹©å‚æ•°
```bash
--onnxrt               # ä½¿ç”¨ ONNX Runtime
--trt                  # ä½¿ç”¨ TensorRT
--tf                   # ä½¿ç”¨ TensorFlow
--pluginref            # ä½¿ç”¨ Plugin CPU Reference
```

### æ¨¡å‹ç±»å‹å’ŒåŠ è½½å‚æ•°
```bash
--model-type TYPE      # æŒ‡å®šè¾“å…¥æ¨¡å‹ç±»å‹
                      # frozen: TensorFlow å†»ç»“å›¾
                      # keras: Keras æ¨¡å‹
                      # ckpt: TensorFlow æ£€æŸ¥ç‚¹ç›®å½•
                      # onnx: ONNX æ¨¡å‹
                      # engine: TensorRT å¼•æ“
                      # uff: UFF æ–‡ä»¶ [å·²å¼ƒç”¨]
                      # trt-network-script: TensorRT ç½‘ç»œè„šæœ¬
                      # caffe: Caffe prototxt [å·²å¼ƒç”¨]
                      
--input-shapes         # æ¨¡å‹è¾“å…¥å½¢çŠ¶ï¼Œæ ¼å¼: name:[shape]
                      # ä¾‹: --input-shapes image:[1,3,224,224] other:[10]
```

### ONNX æ¨¡å‹å¤„ç†å‚æ•°
```bash
--shape-inference     # å¯ç”¨ ONNX å½¢çŠ¶æ¨ç†
--no-onnxruntime-shape-inference  # ç¦ç”¨ ONNX Runtime å½¢çŠ¶æ¨ç†
--external-data-dir DIR           # å¤–éƒ¨æ•°æ®ç›®å½•è·¯å¾„
--ignore-external-data           # å¿½ç•¥å¤–éƒ¨æ•°æ®ï¼Œä»…åŠ è½½æ¨¡å‹ç»“æ„
--onnx-outputs OUTPUTS          # æŒ‡å®š ONNX è¾“å‡ºå¼ é‡
--onnx-exclude-outputs OUTPUTS  # æ’é™¤ç‰¹å®š ONNX è¾“å‡ºå¼ é‡
--fp-to-fp16                    # è½¬æ¢æ‰€æœ‰æµ®ç‚¹å¼ é‡ä¸º FP16
--save-onnx PATH                # ä¿å­˜ ONNX æ¨¡å‹è·¯å¾„
--save-external-data [PATH]     # ä¿å­˜å¤–éƒ¨æ•°æ®åˆ°æ–‡ä»¶
--external-data-size-threshold SIZE  # å¤–éƒ¨æ•°æ®å¤§å°é˜ˆå€¼
```

### ONNX Runtime é…ç½®å‚æ•°
```bash
--providers PROVIDERS  # æ‰§è¡Œæä¾›ç¨‹åºï¼Œå¦‚ CPUExecutionProvider
                      # ä¾‹: --providers cuda cpu
```

### è¾“å…¥æ•°æ®å‚æ•°
```bash
--load-inputs FILE     # ä» JSON æ–‡ä»¶åŠ è½½è¾“å…¥æ•°æ®
--save-inputs FILE     # ä¿å­˜ç”Ÿæˆçš„è¾“å…¥æ•°æ®
--data-loader-script   # è‡ªå®šä¹‰æ•°æ®åŠ è½½è„šæœ¬
--data-loader-func-name NAME  # æ•°æ®åŠ è½½å‡½æ•°å
--seed SEED           # éšæœºæ•°ç§å­ï¼Œç¡®ä¿å¯é‡å¤æ€§
--val-range RANGE     # è¾“å…¥å€¼èŒƒå›´ï¼Œæ ¼å¼: [min,max] æˆ– input:[min,max]
--iterations NUM      # æ¨ç†è¿­ä»£æ¬¡æ•°
--data-loader-backend-module  # æ•°æ®åŠ è½½åç«¯ (numpy/torch)
```

### è¾“å‡ºæ§åˆ¶å‚æ•°
```bash
--save-outputs FILE   # ä¿å­˜æ‰€æœ‰æ¡†æ¶çš„è¾“å‡ºç»“æœ
--mark-all           # å°†æ‰€æœ‰ä¸­é—´å±‚æ ‡è®°ä¸ºè¾“å‡º
--onnx-outputs       # æŒ‡å®š ONNX æ¨¡å‹çš„è¾“å‡ºå±‚
--exclude-outputs    # æ’é™¤ç‰¹å®šè¾“å‡ºå±‚
```

### TensorRT ç‰¹å®šå‚æ•°
```bash
# åŸºç¡€ç²¾åº¦è®¾ç½®
--tf32              # å¯ç”¨ TF32 ç²¾åº¦
--fp16              # å¯ç”¨ FP16 ç²¾åº¦
--bf16              # å¯ç”¨ BF16 ç²¾åº¦
--fp8               # å¯ç”¨ FP8 ç²¾åº¦
--int8              # å¯ç”¨ INT8 é‡åŒ–

# å½¢çŠ¶é…ç½®
--trt-min-shapes SHAPES    # æœ€å°è¾“å…¥å½¢çŠ¶ (åŠ¨æ€å½¢çŠ¶)
--trt-opt-shapes SHAPES    # ä¼˜åŒ–è¾“å…¥å½¢çŠ¶ (æœ€ä½³æ€§èƒ½)
--trt-max-shapes SHAPES    # æœ€å¤§è¾“å…¥å½¢çŠ¶ (åŠ¨æ€å½¢çŠ¶)

# é‡åŒ–é…ç½®
--calibration-cache PATH   # INT8 æ ¡å‡†ç¼“å­˜è·¯å¾„
--calib-base-cls CLASS     # æ ¡å‡†åŸºç±» (å¦‚ IInt8MinMaxCalibrator)
--quantile QUANTILE        # IInt8LegacyCalibrator åˆ†ä½æ•°
--regression-cutoff CUTOFF # IInt8LegacyCalibrator å›å½’æˆªæ­¢

# å¼•æ“ä¼˜åŒ–
--precision-constraints MODE  # ç²¾åº¦çº¦æŸæ¨¡å¼ (prefer/obey/none)
--sparse-weights           # å¯ç”¨ç¨€ç–æƒé‡ä¼˜åŒ–
--version-compatible       # æ„å»ºç‰ˆæœ¬å…¼å®¹å¼•æ“
--exclude-lean-runtime     # æ’é™¤ç²¾ç®€è¿è¡Œæ—¶
--builder-optimization-level LEVEL  # æ„å»ºå™¨ä¼˜åŒ–çº§åˆ«
--hardware-compatibility-level LEVEL # ç¡¬ä»¶å…¼å®¹çº§åˆ«

# å†…å­˜å’Œæ€§èƒ½
--pool-limit POOL:SIZE     # å†…å­˜æ± é™åˆ¶
--max-aux-streams NUM      # æœ€å¤§è¾…åŠ©æµæ•°é‡
--tactic-sources SOURCES   # ç­–ç•¥æº (cublas, cudnn ç­‰)
--save-tactics PATH        # ä¿å­˜ç­–ç•¥é‡æ’­æ–‡ä»¶
--load-tactics PATH        # åŠ è½½ç­–ç•¥é‡æ’­æ–‡ä»¶

# ç¼“å­˜é…ç½®
--load-timing-cache PATH   # åŠ è½½æ—¶åºç¼“å­˜
--save-timing-cache PATH   # ä¿å­˜æ—¶åºç¼“å­˜
--error-on-timing-cache-miss  # æ—¶åºç¼“å­˜ç¼ºå¤±æ—¶æŠ¥é”™
--disable-compilation-cache   # ç¦ç”¨ç¼–è¯‘ç¼“å­˜

# é«˜çº§åŠŸèƒ½
--weight-streaming         # å¯ç”¨æƒé‡æµ
--weight-streaming-budget SIZE  # æƒé‡æµé¢„ç®—
--strongly-typed           # å¼ºç±»å‹ç½‘ç»œ
--refittable               # å…è®¸é‡æ–°æ‹Ÿåˆæƒé‡
--strip-plan               # æ„å»ºæ—¶å‰¥ç¦»å¯é‡æ–°æ‹Ÿåˆæƒé‡

# DLA æ”¯æŒ
--use-dla                  # ä½¿ç”¨ DLA ä½œä¸ºé»˜è®¤è®¾å¤‡
--allow-gpu-fallback       # å…è®¸ DLA ä¸æ”¯æŒçš„å±‚å›é€€åˆ° GPU

# æ’ä»¶å’Œæ‰©å±•
--plugins PATHS            # åŠ è½½æ’ä»¶åº“è·¯å¾„
--onnx-flags FLAGS         # ONNX è§£æå™¨æ ‡å¿—
--plugin-instancenorm      # å¼ºåˆ¶ä½¿ç”¨æ’ä»¶ InstanceNorm

# å¼•æ“æ–‡ä»¶æ“ä½œ
--save-engine PATH         # ä¿å­˜ TensorRT å¼•æ“
--load-runtime PATH        # åŠ è½½è¿è¡Œæ—¶

# æ¨ç†é…ç½®
--optimization-profile IDX # æ¨ç†æ—¶ä½¿ç”¨çš„ä¼˜åŒ–é…ç½®æ–‡ä»¶ç´¢å¼•
--allocation-strategy MODE # æ¿€æ´»å†…å­˜åˆ†é…ç­–ç•¥ (static/profile/runtime)
```

### æ¯”è¾ƒå’ŒéªŒè¯å‚æ•°
```bash
# åŸºç¡€æ¯”è¾ƒé…ç½®
--validate               # æ£€æŸ¥è¾“å‡ºä¸­çš„ NaN å’Œ Inf å€¼
--fail-fast             # å¿«é€Ÿå¤±è´¥ (ç¬¬ä¸€ä¸ªå¤±è´¥ååœæ­¢)
--compare {simple,indices}  # æ¯”è¾ƒå‡½æ•°ç±»å‹
--compare-func-script SCRIPT  # è‡ªå®šä¹‰æ¯”è¾ƒå‡½æ•°è„šæœ¬
--load-outputs PATHS    # åŠ è½½å…ˆå‰ä¿å­˜çš„è¾“å‡ºç»“æœ
--no-shape-check        # ç¦ç”¨å½¢çŠ¶æ£€æŸ¥

# å®¹å·®è®¾ç½® (simple æ¯”è¾ƒå‡½æ•°)
--rtol RTOL             # ç›¸å¯¹è¯¯å·®å®¹å¿åº¦ï¼Œæ”¯æŒæŒ‰è¾“å‡ºæŒ‡å®š
                       # ä¾‹: --rtol 1e-5 output1:1e-4
--atol ATOL             # ç»å¯¹è¯¯å·®å®¹å¿åº¦ï¼Œæ”¯æŒæŒ‰è¾“å‡ºæŒ‡å®š
                       # ä¾‹: --atol 1e-5 output1:1e-4
--check-error-stat STAT # æ£€æŸ¥çš„è¯¯å·®ç»Ÿè®¡é‡ (max/mean/median)
--infinities-compare-equal  # åŒ¹é…çš„ Â±inf å€¼è§†ä¸ºç›¸ç­‰
--error-quantile QUANTILE   # è¯¯å·®åˆ†ä½æ•°æ¯”è¾ƒ

# ç´¢å¼•æ¯”è¾ƒ (indices æ¯”è¾ƒå‡½æ•°)
--index-tolerance TOL   # ç´¢å¼•å®¹å¿åº¦ï¼Œæ”¯æŒæŒ‰è¾“å‡ºæŒ‡å®š

# ç»“æœå¯è§†åŒ–
--save-heatmaps DIR     # ä¿å­˜è¯¯å·®çƒ­å›¾
--show-heatmaps         # æ˜¾ç¤ºè¯¯å·®çƒ­å›¾
--save-error-metrics-plot DIR  # ä¿å­˜è¯¯å·®æŒ‡æ ‡å›¾
--show-error-metrics-plot      # æ˜¾ç¤ºè¯¯å·®æŒ‡æ ‡å›¾

# åå¤„ç†
--postprocess FUNC      # è¾“å‡ºåå¤„ç†å‡½æ•°
                       # ä¾‹: --postprocess top-5 æˆ– output1:top-3
```

### æ¨ç†é…ç½®å‚æ•°
```bash
--warm-up NUM           # é¢„çƒ­è¿è¡Œæ¬¡æ•°
--use-subprocess        # åœ¨ç‹¬ç«‹å­è¿›ç¨‹ä¸­è¿è¡Œ
--save-outputs PATH     # ä¿å­˜æ‰€æœ‰æ¡†æ¶è¾“å‡ºç»“æœ
```

### æ—¥å¿—å’Œè°ƒè¯•å‚æ•°
```bash
# æ—¥å¿—çº§åˆ«æ§åˆ¶
-v, --verbose           # å¢åŠ æ—¥å¿—è¯¦ç»†ç¨‹åº¦ (å¯å¤šæ¬¡ä½¿ç”¨)
-q, --quiet             # å‡å°‘æ—¥å¿—è¯¦ç»†ç¨‹åº¦ (å¯å¤šæ¬¡ä½¿ç”¨)
--verbosity LEVEL       # æŒ‡å®šæ—¥å¿—è¯¦ç»†çº§åˆ« (INFO/VERBOSE/WARNING ç­‰)
--silent                # ç¦ç”¨æ‰€æœ‰è¾“å‡º

# æ—¥å¿—æ ¼å¼å’Œè¾“å‡º
--log-format FORMAT     # æ—¥å¿—æ ¼å¼é€‰é¡¹
                       # timestamp: åŒ…å«æ—¶é—´æˆ³
                       # line-info: åŒ…å«æ–‡ä»¶å’Œè¡Œå·
                       # no-colors: ç¦ç”¨é¢œè‰²
--log-file PATH         # å°†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶

# è„šæœ¬ç”Ÿæˆå’Œè°ƒè¯•
--gen-script PATH       # ç”Ÿæˆç­‰æ•ˆçš„ Python è„šæœ¬è€Œä¸æ‰§è¡Œ
                       # ç”¨äºç†è§£å’Œè°ƒè¯• polygraphy run çš„è¡Œä¸º
```

### TensorFlow ç›¸å…³å‚æ•° (å¯é€‰)
```bash
# TensorFlow æ¨¡å‹åŠ è½½
--ckpt CHECKPOINT       # æ£€æŸ¥ç‚¹åç§° (ä¸å«æ‰©å±•å)
--tf-outputs OUTPUTS    # TensorFlow è¾“å‡ºå¼ é‡åç§°
--save-pb PATH          # ä¿å­˜ TensorFlow å†»ç»“å›¾
--freeze-graph          # å°è¯•å†»ç»“å›¾

# TensorFlow ä¼šè¯é…ç½®
--gpu-memory-fraction FRAC  # GPU å†…å­˜ä½¿ç”¨æ¯”ä¾‹
--allow-growth          # å…è®¸ GPU å†…å­˜åŠ¨æ€å¢é•¿
--xla                   # å¯ç”¨ XLA åŠ é€Ÿ

# TensorFlow-TensorRT é›†æˆ
--tftrt                 # å¯ç”¨ TF-TRT é›†æˆ
--minimum-segment-size SIZE  # è½¬æ¢ä¸º TensorRT çš„æœ€å°æ®µé•¿åº¦
--dynamic-op            # å¯ç”¨åŠ¨æ€æ¨¡å¼ (è¿è¡Œæ—¶æ„å»ºå¼•æ“)
```

## ğŸ’¡ å®ç”¨ç¤ºä¾‹

### 1. åŸºç¡€ç²¾åº¦éªŒè¯
```bash
# ç®€å•çš„ ONNX Runtime vs TensorRT æ¯”è¾ƒ
polygraphy run resnet50.onnx --onnxrt --trt --workspace 1G

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
polygraphy run resnet50.onnx --onnxrt --trt --verbose
```

### 2. åŠ¨æ€å½¢çŠ¶æ¨¡å‹æ¯”è¾ƒ
```bash
# åŠ¨æ€æ‰¹æ¬¡å¤§å°
polygraphy run model.onnx --onnxrt --trt \
  --trt-min-shapes input:[1,3,224,224] \
  --trt-opt-shapes input:[4,3,224,224] \
  --trt-max-shapes input:[8,3,224,224] \
  --input-shapes input:[4,3,224,224]
```

### 3. INT8 é‡åŒ–ç²¾åº¦å¯¹æ¯”
```bash
# INT8 vs FP32 æ¯”è¾ƒ
polygraphy run model.onnx --onnxrt --trt --int8 \
  --calibration-cache calib.cache \
  --save-outputs int8_outputs.json
```

### 4. è‡ªå®šä¹‰è¾“å…¥æ•°æ®
```bash
# ä½¿ç”¨çœŸå®æ•°æ®
polygraphy run model.onnx --onnxrt --trt \
  --load-inputs real_data.json \
  --save-outputs results.json
```

### 5. é€å±‚ç²¾åº¦åˆ†æ
```bash
# æ ‡è®°æ‰€æœ‰å±‚è¾“å‡º
polygraphy run model.onnx --onnxrt --trt --onnx-outputs mark\ all \
  --save-outputs layer_outputs.json

# ä»…æ¯”è¾ƒç‰¹å®šå±‚
polygraphy run model.onnx --onnxrt --trt \
  --onnx-outputs conv1_output relu1_output \
  --onnx-exclude-outputs final_output
```

### 6. é«˜çº§ TensorRT ä¼˜åŒ–
```bash
# å¤šç²¾åº¦å¯¹æ¯”æµ‹è¯•
polygraphy run model.onnx --onnxrt --trt --fp16 \
  --rtol 1e-3 --atol 1e-3 \
  --builder-optimization-level 5 \
  --save-engine optimized_fp16.engine

# æƒé‡æµå’Œå†…å­˜ä¼˜åŒ–
polygraphy run model.onnx --trt --strongly-typed --weight-streaming \
  --weight-streaming-budget 1G \
  --pool-limit workspace:2G \
  --max-aux-streams 4
```

### 7. é‡åŒ–ç²¾åº¦éªŒè¯
```bash
# INT8 é‡åŒ–å®Œæ•´æµç¨‹
polygraphy run model.onnx --onnxrt --trt --int8 \
  --data-loader-script calibration_data.py \
  --calibration-cache int8.cache \
  --calib-base-cls IInt8MinMaxCalibrator \
  --rtol 5e-2 --atol 1e-2
```

### 8. è°ƒè¯•å’Œåˆ†æ
```bash
# ç”Ÿæˆè°ƒè¯•è„šæœ¬
polygraphy run model.onnx --onnxrt --trt \
  --gen-script debug_comparison.py

# è¯¦ç»†æ—¥å¿—è°ƒè¯•
polygraphy run model.onnx --onnxrt --trt \
  --verbose --verbose \
  --log-format timestamp line-info \
  --log-file debug.log

# è¯¯å·®åˆ†æå’Œå¯è§†åŒ–
polygraphy run model.onnx --onnxrt --trt \
  --validate --fail-fast \
  --save-heatmaps error_analysis/ \
  --save-error-metrics-plot plots/ \
  --check-error-stat max mean
```

### 9. æ‰¹é‡æ¨¡å‹æµ‹è¯•
```bash
# åˆ›å»ºæ‰¹é‡æµ‹è¯•è„šæœ¬
#!/bin/bash
for precision in fp32 fp16 int8; do
    echo "Testing with $precision precision"
    polygraphy run model.onnx --onnxrt --trt --$precision \
      --save-outputs "results/model_${precision}.json" \
      --rtol 1e-3 --atol 1e-3
done

# æ¯”è¾ƒä¸åŒç²¾åº¦ç»“æœ
polygraphy run model.onnx \
  --load-outputs results/model_fp32.json results/model_fp16.json \
  --compare simple --rtol 1e-2
```

### 10. å¤æ‚è¾“å…¥æ•°æ®åœºæ™¯
```bash
# å¤šè¾“å…¥æ¨¡å‹
polygraphy run multi_input_model.onnx --onnxrt --trt \
  --input-shapes image:[1,3,224,224] mask:[1,1,224,224] \
  --val-range image:[0,1] mask:[0,1] \
  --data-loader-backend-module torch

# åŠ¨æ€å½¢çŠ¶å®Œæ•´æµ‹è¯•
polygraphy run dynamic_model.onnx --onnxrt --trt \
  --trt-min-shapes input:[1,3,224,224] \
  --trt-opt-shapes input:[4,3,224,224] \
  --trt-max-shapes input:[8,3,224,224] \
  --input-shapes input:[2,3,224,224] input:[6,3,224,224] \
  --iterations 10
```

## ğŸ”§ æ•°æ®åŠ è½½å™¨è„šæœ¬

### åŸºæœ¬æ•°æ®åŠ è½½å™¨ç¤ºä¾‹
```python
# data_loader.py
import numpy as np

def load_data():
    """
    ç”Ÿæˆå™¨å‡½æ•°ï¼Œäº§ç”Ÿè¾“å…¥æ•°æ®
    è¿”å›å­—å…¸å½¢å¼: {"input_name": numpy_array}
    """
    for i in range(10):  # ç”Ÿæˆ10ç»„æ•°æ®
        yield {
            "input": np.random.randn(1, 3, 224, 224).astype(np.float32)
        }

# ä½¿ç”¨æ–¹å¼
# polygraphy run model.onnx --onnxrt --trt --data-loader-script data_loader.py
```

### çœŸå®æ•°æ®åŠ è½½å™¨
```python
# real_data_loader.py
import cv2
import numpy as np
import os

def load_data():
    """åŠ è½½çœŸå®å›¾åƒæ•°æ®"""
    image_dir = "test_images"
    for img_file in os.listdir(image_dir):
        if img_file.endswith(('.jpg', '.png')):
            img_path = os.path.join(image_dir, img_file)
            image = cv2.imread(img_path)
            image = cv2.resize(image, (224, 224))
            image = image.transpose(2, 0, 1)  # HWC -> CHW
            image = image[np.newaxis, :] / 255.0  # å½’ä¸€åŒ–
            
            yield {"input": image.astype(np.float32)}
```

### å¤šè¾“å…¥æ•°æ®åŠ è½½å™¨
```python
# multi_input_loader.py
import numpy as np
import torch

def load_data():
    """å¤šè¾“å…¥æ¨¡å‹æ•°æ®åŠ è½½å™¨"""
    batch_size = 1
    seq_len = 128
    vocab_size = 30522
    
    for i in range(10):  # ç”Ÿæˆ10æ‰¹æ•°æ®
        # ç”Ÿæˆæ–‡æœ¬è¾“å…¥ ID
        input_ids = np.random.randint(0, vocab_size, (batch_size, seq_len))
        
        # ç”Ÿæˆæ³¨æ„åŠ›æ©ç 
        attention_mask = np.ones((batch_size, seq_len))
        
        # ç”Ÿæˆä½ç½®ç¼–ç 
        position_ids = np.arange(seq_len).reshape(1, -1)
        position_ids = np.tile(position_ids, (batch_size, 1))
        
        yield {
            "input_ids": input_ids.astype(np.int64),
            "attention_mask": attention_mask.astype(np.int64),
            "position_ids": position_ids.astype(np.int64)
        }
```

### INT8 æ ¡å‡†æ•°æ®åŠ è½½å™¨
```python
# calibration_data.py
import cv2
import numpy as np
import os
from pathlib import Path

def load_data():
    """INT8 æ ¡å‡†æ•°æ®åŠ è½½å™¨"""
    calib_images_dir = Path("calibration_images")
    image_files = list(calib_images_dir.glob("*.jpg")) + list(calib_images_dir.glob("*.png"))
    
    # é™åˆ¶æ ¡å‡†æ•°æ®æ•°é‡ (é€šå¸¸ 100-1000 å¼ å›¾ç‰‡è¶³å¤Ÿ)
    image_files = image_files[:500]
    
    for img_path in image_files:
        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        image = cv2.imread(str(img_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (224, 224))
        
        # å½’ä¸€åŒ–åˆ° [0, 1]
        image = image.astype(np.float32) / 255.0
        
        # æ ‡å‡†åŒ– (ImageNet å‡å€¼å’Œæ ‡å‡†å·®)
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = (image - mean) / std
        
        # è½¬æ¢ä¸º NCHW æ ¼å¼
        image = image.transpose(2, 0, 1)
        image = image[np.newaxis, :]
        
        yield {"input": image.astype(np.float32)}
```

### åŠ¨æ€å½¢çŠ¶æ•°æ®åŠ è½½å™¨
```python
# dynamic_shape_loader.py
import numpy as np

def load_data():
    """åŠ¨æ€å½¢çŠ¶æ•°æ®åŠ è½½å™¨"""
    # å®šä¹‰ä¸åŒçš„æ‰¹æ¬¡å¤§å°å’Œåºåˆ—é•¿åº¦
    batch_sizes = [1, 2, 4, 8]
    seq_lengths = [64, 128, 256, 512]
    
    for batch_size in batch_sizes:
        for seq_len in seq_lengths:
            # ç”Ÿæˆéšæœºè¾“å…¥æ•°æ®
            input_data = np.random.randn(batch_size, 3, 224, 224).astype(np.float32)
            
            yield {"input": input_data}
            
            # æ¯ç§é…ç½®åªç”Ÿæˆä¸€æ¬¡
            break
```

## ğŸ“Š ç»“æœåˆ†æ

### è¾“å‡ºæ ¼å¼ç†è§£
```json
{
  "inference_results": {
    "onnxrt-runner": {
      "output": [æ•°ç»„æ•°æ®]
    },
    "trt-runner": {
      "output": [æ•°ç»„æ•°æ®]  
    }
  },
  "comparison_results": {
    "output": {
      "max_error": 0.001,
      "mean_error": 0.0001,
      "passed": true
    }
  }
}
```

### è¯¯å·®ç»Ÿè®¡è§£è¯»
- **max_error**: æœ€å¤§ç»å¯¹è¯¯å·®
- **mean_error**: å¹³å‡è¯¯å·®
- **passed**: æ˜¯å¦é€šè¿‡å®¹å·®æ£€æŸ¥
- **error_distribution**: è¯¯å·®åˆ†å¸ƒç»Ÿè®¡

## âš ï¸ å¸¸è§é—®é¢˜

### 1. å†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
polygraphy run model.onnx --onnxrt --trt --input-shapes input:[1,3,224,224]

# å¢åŠ å·¥ä½œç©ºé—´
polygraphy run model.onnx --onnxrt --trt --workspace 2G
```

### 2. ç²¾åº¦ä¸åŒ¹é…
```bash
# è°ƒæ•´å®¹å·®
polygraphy run model.onnx --onnxrt --trt --rtol 1e-3 --atol 1e-3

# ä½¿ç”¨ FP32 ç²¾åº¦
polygraphy run model.onnx --onnxrt --trt --tf32
```

### 3. åŠ¨æ€å½¢çŠ¶é—®é¢˜
```bash
# æ˜ç¡®æŒ‡å®šæ‰€æœ‰å½¢çŠ¶å‚æ•°
polygraphy run model.onnx --onnxrt --trt \
  --trt-min-shapes input:[1,3,224,224] \
  --trt-opt-shapes input:[1,3,224,224] \
  --trt-max-shapes input:[1,3,224,224]
```

## ğŸš€ é«˜çº§ç”¨æ³•

### 1. æ‰¹é‡æµ‹è¯•
```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
for model in models/*.onnx; do
    echo "Testing $model"
    polygraphy run "$model" --onnxrt --trt --save-outputs "results/$(basename $model).json"
done
```

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•
```bash
# å¯ç”¨æ€§èƒ½æµ‹é‡
polygraphy run model.onnx --onnxrt --trt --warm-up-runs 10 --timing-cache timing.cache
```

### 3. è°ƒè¯•æ¨¡å¼  
```bash
# è¯¦ç»†è°ƒè¯•ä¿¡æ¯
polygraphy run model.onnx --onnxrt --trt -vv --log-file debug.log
```

## ğŸ“ˆ æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–å»ºè®®
```bash
# å¤§æ¨¡å‹å†…å­˜ä¼˜åŒ–
polygraphy run large_model.onnx --onnxrt --trt \
  --pool-limit workspace:4G dla_local_dram:1G \
  --allocation-strategy runtime \
  --use-subprocess

# æƒé‡æµä¼˜åŒ– (é€‚ç”¨äºè¶…å¤§æ¨¡å‹)
polygraphy run huge_model.onnx --trt \
  --weight-streaming --weight-streaming-budget 50% \
  --strongly-typed --refittable
```

### ç²¾åº¦ä¼˜åŒ–ç­–ç•¥
```bash
# æ¸è¿›å¼ç²¾åº¦æµ‹è¯•
# 1. é¦–å…ˆæµ‹è¯• FP32
polygraphy run model.onnx --onnxrt --trt --save-outputs fp32_baseline.json

# 2. æµ‹è¯• FP16 å¹¶ä¸ FP32 æ¯”è¾ƒ
polygraphy run model.onnx --onnxrt --trt --fp16 \
  --load-outputs fp32_baseline.json \
  --rtol 1e-2 --atol 1e-3

# 3. æµ‹è¯• INT8 å¹¶è°ƒæ•´å®¹å·®
polygraphy run model.onnx --onnxrt --trt --int8 \
  --calibration-cache calibration.cache \
  --load-outputs fp32_baseline.json \
  --rtol 5e-2 --atol 1e-2
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```bash
# å®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶
polygraphy run model.onnx --onnxrt --trt --fp16 \
  --warm-up 10 --iterations 100 \
  --save-timing-cache timing.cache \
  --builder-optimization-level 5 \
  --tactic-sources cublas cudnn \
  --max-aux-streams 4
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [convert - æ¨¡å‹è½¬æ¢](./convert.md) - æ¨¡å‹æ ¼å¼è½¬æ¢
- [debug - è°ƒè¯•å·¥å…·](./debug.md) - è¿›ä¸€æ­¥è°ƒè¯•å¤±è´¥æ¡ˆä¾‹
- [inspect - æ¨¡å‹åˆ†æ](./inspect.md) - åˆ†ææ¨¡å‹ç»“æ„

---

*`polygraphy run` æ˜¯å‘ç°å’Œè°ƒè¯•æ¨ç†é—®é¢˜çš„ç¬¬ä¸€æ­¥ï¼ŒæŒæ¡å…¶ç”¨æ³•å¯¹äºæ¨¡å‹éƒ¨ç½²è‡³å…³é‡è¦ã€‚*